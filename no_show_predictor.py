"""
Sistema de Previs√£o de No-Show em Consultas Ambulatoriais
Projeto para Hackathon IA 2025 - Regula√ß√£o em Sa√∫de P√∫blica

Este sistema utiliza Machine Learning para prever a probabilidade de pacientes 
faltarem √†s consultas agendadas, permitindo otimiza√ß√£o de recursos e redu√ß√£o de filas.

Autor: [Seu Nome]
Data: Setembro 2025
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import warnings
warnings.filterwarnings('ignore')

class NoShowPredictor:
    """
    Sistema de previs√£o de no-show para consultas ambulatoriais
    Baseado nos desafios do Hackathon IA 2025 - Coppe/UFRJ
    """
    
    def __init__(self):
        self.model = None
        self.label_encoders = {}
        self.scaler = StandardScaler()
        self.feature_importance = None
        
    def generate_synthetic_data(self, n_samples=10000):
        """
        Gera dados sint√©ticos baseados na estrutura do Data Lake Rio de Janeiro
        Simula as tabelas: marcacao, solicitacao, e dados demogr√°ficos
        """
        np.random.seed(42)
        
        # Baseado na tabela 'marcacao' do Data Lake
        data = {
            # Demografia do paciente
            'paciente_faixa_etaria': np.random.choice(['0-14', '15-29', '30-44', '45-59', '60-74', '75+'], 
                                                    n_samples, p=[0.15, 0.20, 0.25, 0.20, 0.15, 0.05]),
            'paciente_sexo': np.random.choice(['M', 'F'], n_samples, p=[0.45, 0.55]),
            
            # Caracter√≠sticas da solicita√ß√£o
            'central_solicitante': np.random.choice(['CENTRO', 'ZONA_NORTE', 'ZONA_SUL', 'ZONA_OESTE', 
                                                   'BAIXADA', 'NITEROI'], n_samples),
            'tipo_procedimento': np.random.choice(['CONSULTA_ESPECIALISTA', 'EXAME_IMAGEM', 
                                                 'EXAME_LAB', 'CIRURGIA_ELETIVA'], n_samples),
            'vaga_solicitada_tp': np.random.choice(['1_VEZ', 'RETORNO'], n_samples, p=[0.6, 0.4]),
            
            # Temporal
            'dias_antecedencia_agendamento': np.random.exponential(scale=15, size=n_samples).astype(int),
            'dia_semana_consulta': np.random.choice(['SEG', 'TER', 'QUA', 'QUI', 'SEX'], n_samples),
            'turno_consulta': np.random.choice(['MANHA', 'TARDE'], n_samples, p=[0.6, 0.4]),
            'mes_consulta': np.random.randint(1, 13, n_samples),
            
            # Hist√≥rico do paciente
            'consultas_anteriores': np.random.poisson(lam=2, size=n_samples),
            'no_shows_anteriores': np.random.poisson(lam=0.5, size=n_samples),
            'tempo_ultima_consulta_dias': np.random.exponential(scale=60, size=n_samples).astype(int),
            
            # Caracter√≠sticas da unidade
            'distancia_unidade_km': np.random.exponential(scale=8, size=n_samples),
            'unidade_porte': np.random.choice(['PEQUENO', 'MEDIO', 'GRANDE'], n_samples, p=[0.4, 0.4, 0.2]),
        }
        
        df = pd.DataFrame(data)
        
        # Criar vari√°vel target baseada em regras realistas
        no_show_prob = 0.15  # Taxa base de no-show (~15%)
        
        # Fatores que aumentam probabilidade de no-show
        prob_adjustments = np.zeros(n_samples)
        
        # Faixa et√°ria (jovens adultos faltam mais)
        prob_adjustments += np.where(df['paciente_faixa_etaria'].isin(['15-29', '30-44']), 0.05, 0)
        
        # Anteced√™ncia (muito cedo ou muito em cima da hora)
        prob_adjustments += np.where(df['dias_antecedencia_agendamento'] > 30, 0.08, 0)
        prob_adjustments += np.where(df['dias_antecedencia_agendamento'] < 3, 0.06, 0)
        
        # Hist√≥rico de no-shows
        prob_adjustments += df['no_shows_anteriores'] * 0.15
        
        # Dist√¢ncia da unidade
        prob_adjustments += np.where(df['distancia_unidade_km'] > 15, 0.07, 0)
        
        # Primeira vez vs retorno
        prob_adjustments += np.where(df['vaga_solicitada_tp'] == '1_VEZ', 0.04, -0.02)
        
        # Segunda-feira e sexta-feira
        prob_adjustments += np.where(df['dia_semana_consulta'].isin(['SEG']), 0.03, 0)
        
        # Gerar target
        final_probs = np.clip(no_show_prob + prob_adjustments, 0.01, 0.95)
        df['no_show'] = np.random.binomial(1, final_probs)
        
        return df
    
    def preprocess_data(self, df):
        """Preprocessa os dados para o modelo"""
        df_processed = df.copy()
        
        # Encoding de vari√°veis categ√≥ricas
        categorical_cols = ['paciente_faixa_etaria', 'paciente_sexo', 'central_solicitante', 
                           'tipo_procedimento', 'vaga_solicitada_tp', 'dia_semana_consulta', 
                           'turno_consulta', 'unidade_porte']
        
        for col in categorical_cols:
            if col not in self.label_encoders:
                self.label_encoders[col] = LabelEncoder()
                df_processed[col] = self.label_encoders[col].fit_transform(df_processed[col])
            else:
                df_processed[col] = self.label_encoders[col].transform(df_processed[col])
        
        # Features derivadas
        df_processed['taxa_no_show_historica'] = np.where(
            df_processed['consultas_anteriores'] > 0,
            df_processed['no_shows_anteriores'] / df_processed['consultas_anteriores'],
            0
        )
        
        df_processed['paciente_novo'] = (df_processed['consultas_anteriores'] == 0).astype(int)
        df_processed['distancia_categoria'] = pd.cut(df_processed['distancia_unidade_km'], 
                                                   bins=[0, 5, 15, 50], labels=['PERTO', 'MEDIO', 'LONGE'])
        df_processed['distancia_categoria'] = LabelEncoder().fit_transform(df_processed['distancia_categoria'])
        
        return df_processed
    
    def train_model(self, df):
        """Treina o modelo de previs√£o"""
        df_processed = self.preprocess_data(df)
        
        # Separar features e target
        feature_cols = [col for col in df_processed.columns if col not in ['no_show']]
        X = df_processed[feature_cols]
        y = df_processed['no_show']
        
        # Split treino/teste
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
        
        # Normalizar features num√©ricas
        numeric_cols = X.select_dtypes(include=[np.number]).columns
        X_train_scaled = X_train.copy()
        X_test_scaled = X_test.copy()
        X_train_scaled[numeric_cols] = self.scaler.fit_transform(X_train[numeric_cols])
        X_test_scaled[numeric_cols] = self.scaler.transform(X_test[numeric_cols])
        
        # Treinar modelo ensemble
        self.model = GradientBoostingClassifier(
            n_estimators=100,
            learning_rate=0.1,
            max_depth=6,
            random_state=42
        )
        
        self.model.fit(X_train_scaled, y_train)
        
        # Avaliar modelo
        y_pred = self.model.predict(X_test_scaled)
        y_pred_proba = self.model.predict_proba(X_test_scaled)[:, 1]
        
        print("=== AVALIA√á√ÉO DO MODELO ===")
        print(f"AUC-ROC Score: {roc_auc_score(y_test, y_pred_proba):.3f}")
        print("\nClassification Report:")
        print(classification_report(y_test, y_pred))
        
        # Feature importance
        self.feature_importance = pd.DataFrame({
            'feature': feature_cols,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        return X_test_scaled, y_test, y_pred_proba
    
    def predict_no_show_probability(self, patient_data):
        """Prediz probabilidade de no-show para um paciente espec√≠fico"""
        if self.model is None:
            raise ValueError("Modelo n√£o foi treinado ainda!")
        
        df_patient = pd.DataFrame([patient_data])
        df_processed = self.preprocess_data(df_patient)
        
        # Aplicar mesma normaliza√ß√£o
        feature_cols = [col for col in df_processed.columns if col not in ['no_show']]
        X_patient = df_processed[feature_cols]
        
        numeric_cols = X_patient.select_dtypes(include=[np.number]).columns
        X_patient_scaled = X_patient.copy()
        X_patient_scaled[numeric_cols] = self.scaler.transform(X_patient[numeric_cols])
        
        probability = self.model.predict_proba(X_patient_scaled)[0, 1]
        return probability
    
    def generate_insights(self):
        """Gera insights para gest√£o hospitalar"""
        if self.feature_importance is None:
            return "Modelo n√£o treinado ainda."
        
        insights = []
        top_features = self.feature_importance.head(5)
        
        insights.append("=== INSIGHTS PARA GEST√ÉO AMBULATORIAL ===\n")
        insights.append("üéØ FATORES MAIS IMPORTANTES PARA NO-SHOW:")
        for idx, row in top_features.iterrows():
            insights.append(f"   ‚Ä¢ {row['feature']}: {row['importance']:.3f}")
        
        insights.append(f"\nüí° RECOMENDA√á√ïES ESTRAT√âGICAS:")
        insights.append("   ‚Ä¢ Implementar lembretes via SMS/WhatsApp 2-3 dias antes")
        insights.append("   ‚Ä¢ Criar overbooking inteligente baseado no score de risco")
        insights.append("   ‚Ä¢ Priorizar pacientes com baixo risco para hor√°rios cr√≠ticos")
        insights.append("   ‚Ä¢ Monitorar padr√µes por regi√£o e especialidade")
        insights.append("   ‚Ä¢ Desenvolver campanhas de conscientiza√ß√£o para grupos de alto risco")
        
        return "\n".join(insights)
    
    def plot_analysis(self, X_test, y_test, y_pred_proba):
        """Gera visualiza√ß√µes para an√°lise"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('An√°lise do Sistema de Previs√£o de No-Show', fontsize=16, fontweight='bold')
        
        # 1. Feature Importance
        axes[0,0].barh(self.feature_importance.head(8)['feature'], 
                       self.feature_importance.head(8)['importance'])
        axes[0,0].set_title('Import√¢ncia das Features')
        axes[0,0].set_xlabel('Import√¢ncia')
        
        # 2. Distribui√ß√£o de probabilidades
        axes[0,1].hist(y_pred_proba[y_test==0], alpha=0.5, label='Compareceu', bins=30)
        axes[0,1].hist(y_pred_proba[y_test==1], alpha=0.5, label='No-Show', bins=30)
        axes[0,1].set_title('Distribui√ß√£o de Probabilidades Preditas')
        axes[0,1].set_xlabel('Probabilidade de No-Show')
        axes[0,1].legend()
        
        # 3. Confusion Matrix
        from sklearn.metrics import confusion_matrix
        y_pred_binary = (y_pred_proba > 0.5).astype(int)
        cm = confusion_matrix(y_test, y_pred_binary)
        sns.heatmap(cm, annot=True, fmt='d', ax=axes[1,0], cmap='Blues')
        axes[1,0].set_title('Matriz de Confus√£o')
        axes[1,0].set_ylabel('Real')
        axes[1,0].set_xlabel('Predito')
        
        # 4. ROC Curve
        from sklearn.metrics import roc_curve
        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        axes[1,1].plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc_score(y_test, y_pred_proba):.3f})')
        axes[1,1].plot([0, 1], [0, 1], 'k--', label='Random')
        axes[1,1].set_title('Curva ROC')
        axes[1,1].set_xlabel('Taxa de Falso Positivo')
        axes[1,1].set_ylabel('Taxa de Verdadeiro Positivo')
        axes[1,1].legend()
        
        plt.tight_layout()
        plt.show()

def main():
    """Fun√ß√£o principal - Demonstra√ß√£o do sistema"""
    print("üè• SISTEMA DE PREVIS√ÉO DE NO-SHOW - REGULA√á√ÉO AMBULATORIAL")
    print("=" * 60)
    print("Projeto para Hackathon IA 2025 - Coppe/UFRJ")
    print("Foco: Otimiza√ß√£o de recursos em sa√∫de p√∫blica\n")
    
    # Inicializar sistema
    predictor = NoShowPredictor()
    
    # Gerar dados sint√©ticos baseados no Data Lake Rio
    print("üìä Gerando dados sint√©ticos baseados no Data Lake da Sa√∫de RJ...")
    df = predictor.generate_synthetic_data(n_samples=15000)
    
    print(f"‚úÖ Dataset criado: {len(df)} registros")
    print(f"   Taxa de No-Show: {df['no_show'].mean():.1%}")
    print(f"   Colunas: {', '.join(df.columns[:8])}...\n")
    
    # Treinar modelo
    print("ü§ñ Treinando modelo de Machine Learning...")
    X_test, y_test, y_pred_proba = predictor.train_model(df)
    
    # Exemplo de predi√ß√£o
    print("\n" + "="*60)
    print("üîç EXEMPLO DE PREDI√á√ÉO INDIVIDUAL:")
    
    paciente_exemplo = {
        'paciente_faixa_etaria': '30-44',
        'paciente_sexo': 'F',
        'central_solicitante': 'ZONA_NORTE',
        'tipo_procedimento': 'CONSULTA_ESPECIALISTA',
        'vaga_solicitada_tp': '1_VEZ',
        'dias_antecedencia_agendamento': 45,
        'dia_semana_consulta': 'SEG',
        'turno_consulta': 'MANHA',
        'mes_consulta': 10,
        'consultas_anteriores': 0,
        'no_shows_anteriores': 0,
        'tempo_ultima_consulta_dias': 0,
        'distancia_unidade_km': 22.5,
        'unidade_porte': 'MEDIO'
    }
    
    prob_no_show = predictor.predict_no_show_probability(paciente_exemplo)
    
    print(f"Paciente: Mulher, 30-44 anos, primeira consulta")
    print(f"Agendamento: 45 dias de anteced√™ncia, segunda-feira manh√£")
    print(f"üìà Probabilidade de No-Show: {prob_no_show:.1%}")
    
    if prob_no_show > 0.4:
        print("‚ö†Ô∏è  ALTO RISCO - Recomenda√ß√£o: Contato preventivo + overbooking")
    elif prob_no_show > 0.2:
        print("‚ö° RISCO M√âDIO - Recomenda√ß√£o: Lembrete via SMS")
    else:
        print("‚úÖ BAIXO RISCO - Agendamento normal")
    
    # Insights
    print("\n" + predictor.generate_insights())
    
    # Visualiza√ß√µes
    print("\nüìä Gerando an√°lises visuais...")
    predictor.plot_analysis(X_test, y_test, y_pred_proba)
    
    print("\nüéØ PR√ìXIMOS PASSOS PARA O HACKATHON:")
    print("   1. Integrar com dados reais do Data Lake Rio")
    print("   2. Desenvolver API REST para integra√ß√£o")
    print("   3. Criar dashboard em tempo real")
    print("   4. Implementar sistema de overbooking inteligente")
    print("   5. Adicionar notifica√ß√µes autom√°ticas")

if __name__ == "__main__":
    main()